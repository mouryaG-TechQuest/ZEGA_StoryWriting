# AI Models - Current Status & Quick Fix

## ğŸš¨ URGENT: API Updates Needed

### Groq Models (UPDATED - Use These)
âœ… **Working Models** (as of Nov 2025):
- `llama-3.3-70b-versatile` (NEW - Fastest)
- `llama3-70b-8192` (Stable)
- `llama3-8b-8192` (Fast, smaller)
- `gemma2-9b-it` (Alternative)

âŒ **Decommissioned** (DO NOT USE):
- ~~`llama-3.1-70b-versatile`~~ (removed Oct 2024)
- ~~`mixtral-8x7b-32768`~~ (removed Oct 2024)

### HuggingFace Inference API
âŒ **Status**: Free tier discontinued
âš ï¸ **Note**: `api-inference.huggingface.co` is now PAID ONLY

### Gemini API
âœ… **Working** but quota exceeded (200/day limit)
ğŸ’¡ **Solution**: Wait until tomorrow OR get Groq working

### Ollama (Local)
âš ï¸ **Status**: Timing out (not installed or not running)
ğŸ’» **Optional**: Install from https://ollama.ai/download

## âœ… FIXED IN CODE

Updated `ensemble.py`:
1. âœ… Groq models â†’ `llama-3.3-70b-versatile` + `llama3-70b-8192`  
2. âœ… HuggingFace â†’ Disabled (requires paid plan now)
3. âœ… Ollama timeout â†’ Increased to 8s
4. âœ… Gemini â†’ Handles quota gracefully

## ğŸ¯ Current Working Setup

**Available RIGHT NOW**:
- âœ… **Groq** (should work after restart)
- â° **Gemini** (quota hit - reset tomorrow)
- âš ï¸ **Ollama** (optional - install if needed)

**Quick Test**:
```bash
# Restart ZEGA
cd AIservices
.\venv\Scripts\Activate.ps1
$env:ZEGA_USE_V2="true"
python -m zega.api
```

**Expected Output**:
```
[ENSEMBLE] âœ… Loaded: Gemini 2.0 Flash
[ENSEMBLE] âœ… Loaded: Groq llama-3.3-70b-versatile
[ENSEMBLE] âœ… Loaded: Groq llama3-70b-8192
[ENSEMBLE] ğŸ“ Total teachers loaded: 3-5
```

Then test AI button in frontend - should use Groq now!

## ğŸ”§ If Groq Still Fails

Check your API key validity:
```bash
curl -X POST "https://api.groq.com/openai/v1/chat/completions" \
  -H "Authorization: Bearer YOUR_GROQ_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"model":"llama-3.3-70b-versatile","messages":[{"role":"user","content":"Hello"}]}'
```

Get new key if needed: https://console.groq.com/keys

## ğŸ“Š Model Comparison

| Model | Speed | Quota | Cost | Status |
|-------|-------|-------|------|--------|
| **Groq llama-3.3** | âš¡âš¡âš¡ 0.5s | 30k+/day | FREE | âœ… Updated |
| **Gemini 2.0** | âš¡âš¡ 1-2s | 200/day | FREE | â° Quota hit |
| **Ollama** | âš¡âš¡ 2-5s | Unlimited | FREE | âš ï¸ Optional |
| ~~HuggingFace~~ | âš¡ 5-10s | - | PAID | âŒ Disabled |

## ğŸš€ Recommended Action

**Restart ZEGA** with fixed code:
```bash
# Stop current instance (Ctrl+C)
# Restart
cd C:\Users\hp\Desktop\Working\moreoptimized\StoryWritingProject - MainCopyUsingCluadeSonnet4\AIservices
.\venv\Scripts\Activate.ps1
$env:ZEGA_USE_V2="true"
python -m zega.api
```

**Result**: Groq should work now (free, fast, 30k requests/day) âœ…
